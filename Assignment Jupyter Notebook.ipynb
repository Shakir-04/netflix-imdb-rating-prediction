{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This assignment consists of four sections.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 1 – Data Collection and Preprocessing [20%]**\n",
    "\n",
    "• Select a dataset relevant to a predictive modeling task.\n",
    "\n",
    "• Provide a brief description of the dataset, including feature descriptions and target\n",
    "variable.\n",
    "\n",
    "• Perform the following preprocessing steps:\n",
    "1. Handle any missing values and outliers.\n",
    "2. Encode categorical variables as needed.\n",
    "3. Scale features if necessary.\n",
    "4. Split the data into training and testing sets (e.g., 70% train, 30% test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATASET SOURCE LINK**\n",
    "\n",
    "As required, I have provided a link to the source for my dataset. It is from Kaggle and the link is listed below:\n",
    "\n",
    "https://www.kaggle.com/datasets/octopusteam/full-netflix-dataset/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Load the Dataset**\n",
    "\n",
    "I load the `data.csv` file into a pandas DataFrame. This dataset contains information about Netflix movies and shows.\n",
    "\n",
    "To make sure it works correctly, I then displayed first few rows of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the CSV file into a DataFrame\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Explore the Dataset**\n",
    "\n",
    "To understand the dataset better, I use the following methods:\n",
    "\n",
    "`df.info()` gives me a summary of the DataFrame, including the number of entries, columns, and data types.\n",
    "\n",
    "`df.describe()` provides summary statistics of numerical columns, such as mean, median, and standard deviation.\n",
    "\n",
    "`df.isnull().sum()` checks for missing values across the dataset, and I print the number of missing values in each column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the DataFrame\n",
    "print(\"\\nBasic Information (df.info()):\")\n",
    "df.info()\n",
    "\n",
    "# Display summary statistics for numerical columns\n",
    "print(\"\\nSummary Statistics (df.describe()):\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values (df.isnull().sum()):\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Handle Missing Values**\n",
    "\n",
    "\n",
    "I identify missing values using `df.isnull().sum()` and then fill them.\n",
    "For categorical columns like title and genres, I replace missing values with 'Unknown Title' and 'Unknown Genre' respectively.\n",
    "\n",
    "For numerical columns, I replace missing values with the mean of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display rows with missing values\n",
    "print(\"\\nRows with Missing Values:\")\n",
    "print(df[df.isnull().any(axis=1)])\n",
    "\n",
    "# Fill missing values for categorical columns without using inplace=True\n",
    "df['title'] = df['title'].fillna('Unknown Title')\n",
    "df['genres'] = df['genres'].fillna('Unknown Genre')\n",
    "\n",
    "# Fill missing values for numerical columns\n",
    "df.fillna(df.select_dtypes(include=['number']).mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Verify Missing Values Are Handled**\n",
    "\n",
    "\n",
    "After filling missing values, I use `df.isnull().sum()` again to verify that no missing values remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if missing values are filled\n",
    "print(\"\\nAfter filling missing values (df.isnull().sum()):\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following result show that the replacement worked as intended. \n",
    "\n",
    "`title`: All missing values were replaced with 'Unknown Title' (count is now 0).\n",
    "\n",
    "`genres`: All missing values were replaced with 'Unknown Genre' (count is now 0).\n",
    "\n",
    "`releaseYear`, `imdbAverageRating`, `imdbNumVotes`: Missing numerical values were successfully filled with the column mean (counts are 0).\n",
    "\n",
    "`type` and `availableCountri`es: These columns had no missing values from the start.\n",
    "\n",
    "`imdbId`: This column still **has 1,309 missing values**, likely because it was neither categorical nor numerical and wasn't explicitly handled in my code. I replaced them with a placeholder value like 'Unknown ID'.\n",
    "\n",
    "**The code is shown below**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['imdbId'] = df['imdbId'].fillna('Unknown ID')\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this is done, my DataFrame should have no missing values. The count of 0 indicates that it has no missing values. \n",
    "\n",
    "This also means that:\n",
    "\n",
    " • For `title` and `genres`, missing values were replaced with **Unknown Title** and **Unknown Genre**, respectively. \n",
    " \n",
    " • For numerical columns, missing values were replaced with their respective column means using the `fillna` method. \n",
    " \n",
    " • The dataset is now **complete**, with no missing values left to handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Encode Categorical Data**\n",
    "\n",
    "I encode the `genres` column as categorical data by converting it into numerical codes using pandas' `astype('category').cat.codes` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical columns (example for 'genres')\n",
    "df['genres'] = df['genres'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Split the Dataset into Training and Testing Sets**\n",
    "\n",
    "\n",
    "I split the dataset into features (`X`) and target (`y`), where the target is the `imdbAverageRating`. \n",
    "\n",
    "Then, I use `train_test_split` to divide the data into 80% training and 20% testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X = df.drop('imdbAverageRating', axis=1)  # Features\n",
    "y = df['imdbAverageRating']  # Target\n",
    "\n",
    "# Split into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Output the shapes of training and testing data\n",
    "print(\"\\nTraining and Testing Data Shapes:\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this point, I've completed the data preprocessing steps, including handling missing values, encoding categorical variables, and splitting the data into training and testing sets.**\n",
    "\n",
    "**This prepares the dataset for the next steps, such as model selection and evaluation in future sections.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 2 – Model Selection and Training [25%]**\n",
    "\n",
    "\n",
    "• Select two machine learning algorithms suitable for the dataset and prediction task (e.g.,\n",
    "classification or regression).\n",
    "\n",
    "• For each model, implement the training process in Python, using the training dataset from\n",
    "Section 1.\n",
    "\n",
    "*Required Steps:*\n",
    "\n",
    "1. Define each model and provide a brief explanation of why it is suitable for the task.\n",
    "2. Train both models and save the trained models for evaluation.\n",
    "Present code snippets and a brief justification for each model choice. Include any\n",
    "hyperparameter tuning or optimizations performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***In this section, I will select two machine learning algorithms that are suitable for predicting IMDb average ratings, which is a regression task. I will choose Linear Regression and Random Forest Regressor, and then train both models using the training dataset from Section 1.***\n",
    "\n",
    "1. **Defining Each Model and Provide a Brief Explanation**\n",
    "\n",
    "*Linear Regression*\n",
    "\n",
    "Why it's suitable?: \n",
    "Linear regression is a simple and well-understood model used for regression tasks. It assumes a linear relationship between the features and the target variable (IMDb rating in this case). Linear regression is easy to implement and interpret, making it a good baseline model for this dataset.\n",
    "\n",
    "*Random Forest Regressor*\n",
    "\n",
    "Why it's suitable?: \n",
    "Random Forest is an ensemble method that builds multiple decision trees and combines their predictions. It's particularly useful for datasets with complex patterns, and it can model non-linear relationships between the features and the target. Random Forest is robust against overfitting and is often effective on a wide range of datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Libary Importation and Data Loading**\n",
    "\n",
    "After importing the important libaries, I started by loading the dataset from a CSV file (data.csv) using `Pandas`. I then displayed the first few rows and column names to get an initial understanding of the data's structure. This helped me identify key features and check for any obvious issues as well as that, it allows anyone else to see how the dataset is like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "url = \"data.csv\" \n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Displaying the first few rows to understand the data structure\n",
    "print(df.head())\n",
    "\n",
    "# Checking the column names in your dataset\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Handling Missing Values**\n",
    "\n",
    "Due to the nature of the dataset, there are some missing values. For the models to work properly, it's essential that all values are numerical. If any columns aren't numerical, I would need to either replace the missing values or drop the entire column as a result, I filled the missing values in categorical columns such as `title`, `genres`, `imdbId` and `availableCountries` with placeholder values like **Unknown Title**, **Unknown Genre**, **Unknown Imdb ID** and **Unknown Country**. \n",
    "\n",
    "For numerical columns, I used `df.fillna()` to replace missing values with the mean of the respective column.\n",
    "\n",
    "Finally, I verified that all missing values were handled, and there are no longer any missing entries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking for missing values\n",
    "print(\"\\nMissing Values (df.isnull().sum()):\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Filling missing values for categorical columns\n",
    "df['title'] = df['title'].fillna('Unknown Title')\n",
    "df['genres'] = df['genres'].fillna('Unknown Genre')\n",
    "df['availableCountries'] = df['availableCountries'].fillna('Unknown Country')\n",
    "df['imdbId'] = df['imdbId'].fillna('Unknown IMDb ID')\n",
    "\n",
    "# Filling missing values for numerical columns\n",
    "df.fillna(df.select_dtypes(include=['number']).mean(), inplace=True)\n",
    "\n",
    "# Checking if missing values are filled\n",
    "print(\"\\nAfter filling missing values (df.isnull().sum()):\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My dataset is now free of missing values, and i'm ready to proceed with my  analysis or model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Data Preprocessing**\n",
    "\n",
    "I then performed one-hot encoding on the `genres` and `availableCountries` columns to convert them into numerical values while also using\n",
    "`Label Encoding` for the type column.\n",
    "\n",
    "One-hot encoding is used to like mention, convert fields into numerical values which ensures for better model compatibility and avoids errors.\n",
    "\n",
    "I had to also drop columns like `title, imdbId`, and the original `genres` and `availableCountries` columns as they were either unnecessary for predictions and weren't fully numerical.\n",
    "\n",
    "I also verified that all features were numeric for model compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for 'genres'\n",
    "df = df.join(df['genres'].str.get_dummies(sep=', '))\n",
    "\n",
    "# One-hot encoding for 'availableCountries'\n",
    "df = df.join(df['availableCountries'].str.get_dummies(sep=', '))\n",
    "\n",
    "# Dropping the original 'genres' and 'availableCountries' columns since we've one-hot encoded them\n",
    "df.drop(columns=['genres', 'availableCountries','imdbId'], inplace=True)\n",
    "\n",
    "# Encoding other categorical columns (example for 'type' using LabelEncoder)\n",
    "le = LabelEncoder()\n",
    "df['type'] = le.fit_transform(df['type'])  # You can apply LabelEncoder to other columns like 'type'\n",
    "\n",
    "# Dropping any irrelevant features (e.g., 'title' if it's not needed for prediction)\n",
    "df.drop(columns=['title'], inplace=True)\n",
    "\n",
    "# Final check for data types to ensure everything is numeric\n",
    "print(\"\\nData types of features after encoding (df.dtypes):\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Splitting the Dataset**\n",
    "\n",
    "I split the dataset into features (X) and the target (y) variables which then lead on to further splitting these into training and testing sets, using an 80/20 split ratio, ensuring the test set was representative of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the dataset into training and testing sets\n",
    "X = df.drop('imdbAverageRating', axis=1)  # Features\n",
    "y = df['imdbAverageRating']  # Target\n",
    "\n",
    "# Spliting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Training and Evaluating the Linear Regression Model**\n",
    "\n",
    "I trained a Linear Regression model using the training data and tested its performance on the test dataset. To evaluate how well the model performed, I used the Mean Squared Error (MSE) and R-squared (R²) metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Linear Regression model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Training the model\n",
    "linear_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predicting using the test set\n",
    "y_pred_lr = linear_reg.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Printing results for Linear Regression\n",
    "print(\"Linear Regression Model Results:\")\n",
    "print(f\"Mean Squared Error: {mse_lr}\")\n",
    "print(f\"R-squared: {r2_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of my Linear Regression model gives two key metrics: **Mean Squared Error (MSE)** and **R-squared**. Here's what they suggest:\n",
    "\n",
    "1. **Mean Squared Error (MSE): 0.7876**\n",
    "\n",
    "MSE measures how well the model's predictions match the actual values. It calculates the average of the squared differences between predicted and actual values.\n",
    "\n",
    "A *lower* MSE indicates *better* performance, as the model's predictions are closer to the actual values. In my case, the MSE value is 0.7876, which suggests that while the model is performing reasonably, there's still significant error in its predictions. The exact performance is contextual, but a smaller MSE would indicate better fit.\n",
    "\n",
    "\n",
    "2. **R-squared: 0.2784**\n",
    "\n",
    "R-squared (R²) is a statistical measure of how well the independent variables explain the variation in the dependent variable. In simple terms, it tells you how much of the variability in the target variable is captured by your model.\n",
    "\n",
    "A R-squared value of 0.2784 means that **approximately 27.84% of the variability in the target variable is explained by the model**. This is relatively low, which suggests that the model is not capturing much of the relationship between the features and the target variable.\n",
    "\n",
    "A R² value closer to 1 would indicate that the model is doing a good job of explaining the target variable. An R² closer to 0 suggests that the model is not effective at predicting the target based on the features.\n",
    "\n",
    "**In summary, my linear regression model isn't performing great, but this is a useful starting point to see how the features interact with the target.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Training and Evaluating the Random Forest Regressor**\n",
    "\n",
    "I then trained a Random Forest Regressor model using the training dataset. To assess its performance, I evaluated the predictions on the test dataset using Mean Squared Error (MSE) and R-squared (R²) metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "#Prediciton\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "#Model Evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "#output\n",
    "print(\"Random Forest Regressor Results:\")\n",
    "print(f\"Random Forest Mean Squared Error: {mse_rf}\")\n",
    "print(f\"Random Forest R-squared: {r2_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Based on the results, this suggests a lot things.* \n",
    "\n",
    "First of all, The **MSE** for the Random Forest model is *lower than the MSE from the Linear Regression model (0.6388 vs. 0.7876)*. This indicates that the *Random Forest model is making smaller errors in its predictions, suggesting it’s a better fit for this dataset compared to Linear Regression*.\n",
    "\n",
    "**R-squared**: The R-squared value of 0.4147 means that *about 41.47% of the variability in the target variable is explained by the model*. This is a **significant improvement over the Linear Regression model’s R-squared of 0.2784 (27.84%)**. It indicates that the Random Forest model is better at capturing the relationships between the features and the target variable.\n",
    "\n",
    "**In conclusion, switching to the Random Forest Regressor model has clearly improved the performance, and it's a more suitable model for this task compared to Linear Regression.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, I have now **completed section 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 3 – Prediction and Evaluation [30%]**\n",
    "\n",
    "Use the trained models from Question 2 to generate predictions on the test dataset.\n",
    "\n",
    "Evaluate each model’s performance using appropriate metrics:\n",
    "\n",
    "For classification tasks, report metrics such as accuracy, precision, recall, and F1-\n",
    "score.\n",
    "\n",
    "For regression tasks, report metrics such as Mean Absolute Error (MAE), Root\n",
    "Mean Square Error (RMSE), or R-squared (R²).\n",
    "\n",
    "Compare the models’ performances and discuss which model performs better and why.\n",
    "\n",
    "Include Python code for generating predictions and calculating performance metrics. Interpret\n",
    "and compare the results for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code will showcase how I use the **Linear Regression** and **Random Forest** model to predict the `imdbAverageRating` values. \n",
    "The following code will calculate:\n",
    "\n",
    "1. **Mean Absolute Error (MAE)**: Measures the average absolute difference between predicted and actual values.\n",
    "\n",
    "\n",
    "2. **Root Mean Square Error (RMSE)**: Measures the square root of the average squared difference between predicted and actual values.\n",
    "\n",
    "3. **R-squared (R²)**: Indicates the proportion of variance in the target variable explained by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Generating Predictions\n",
    "y_pred_lr = linear_reg.predict(X_test)  # Predictions from Linear Regression\n",
    "y_pred_rf = rf_model.predict(X_test)   # Predictions from Random Forest Regressor\n",
    "\n",
    "#Evaluating Metrics for Linear Regression\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "rmse_lr = mse_lr ** 0.5\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"\\nLinear Regression Evaluation:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_lr}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse_lr}\")\n",
    "print(f\"R-squared (R²): {r2_lr}\")\n",
    "\n",
    "# Evaluation for Random Forest\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "rmse_rf = mse_rf ** 0.5\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Regressor Evaluation:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_rf}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse_rf}\")\n",
    "print(f\"R-squared (R²): {r2_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging from the results, it is clear that the **Random Forest Regression** outperformed my **Linear Regression Model**\n",
    "\n",
    "One of the main key points to take from the results is that the **Random Forest model** has a significantly lower *Mean Absolute Error (MAE)* and *Root Mean Square Error (RMSE)*.\n",
    "\n",
    "This means the **Random Forest** is making more accurate predictions compared to Linear Regression, with smaller average errors and deviations from the true values\n",
    "\n",
    "As well as that, the *Higher R² value* for **Random Forest** is 0.4318, which is notably higher than the Linear Regression's 0.2830.\n",
    "\n",
    "This indicates that the Random Forest model explains a larger proportion of the variance in the target variable (`imdbAverageRating`) compared to Linear Regression which is important as it allows for more accuracy and understanding which is crucial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it more clear, the code below shows a clear comparison between the two and it's result with a clear statement of what outperforms what."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compare Results\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(\"Linear Regression:\")\n",
    "print(f\"  - MAE: {mae_lr}, RMSE: {rmse_lr}, R²: {r2_lr}\")\n",
    "print(\"Random Forest Regressor:\")\n",
    "print(f\"  - MAE: {mae_rf}, RMSE: {rmse_rf}, R²: {r2_rf}\")\n",
    "\n",
    "if r2_rf > r2_lr:\n",
    "    print(\"\\nThe Random Forest Regressor outperforms the Linear Regression model based on R².\")\n",
    "else:\n",
    "    print(\"\\nThe Linear Regression model performs better based on R².\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 3 is now completed.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 4 – Visualization and Insights [25%]**\n",
    "\n",
    "Visualize key aspects of your machine learning project to help understand model\n",
    "performance and data distribution.\n",
    "\n",
    "Required Visualizations:\n",
    "1. For *classification* tasks, provide a confusion matrix or ROC curve.\n",
    "2. For *regression tasks*, plot predicted values against actual values.\n",
    "3. Visualize feature importance (if applicable) to understand which features\n",
    "contribute most to predictions.\n",
    "\n",
    "Include code for each visualization and describe the insights gained from these visualizations.\n",
    "Summarize your findings and observations based on the entire workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of my scenario, it is a **regression** task and I will like mentioned, plot predicted values against actual values.\n",
    "\n",
    "Starting off, the code below will import the necassary libaries, and I will plot for **Linear Regression** and **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot for Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred_lr, alpha=0.6, label='Linear Regression')\n",
    "sns.lineplot(x=y_test, y=y_test, color='red', label='Ideal Predictions')\n",
    "plt.title(\"Linear Regression: Predicted vs. Actual\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot for Random Forest\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred_rf, alpha=0.6, label='Random Forest Regressor')\n",
    "sns.lineplot(x=y_test, y=y_test, color='red', label='Ideal Predictions')\n",
    "plt.title(\"Random Forest Regressor: Predicted vs. Actual\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As intended, it generated a scatter plot for both models. The visuals indicate a lot of things, I will now break it down\n",
    "\n",
    "**The Predicted/Actual Values**:\n",
    "\n",
    "**Blue Dots**: These represent the predictions made by the linear regression model.\n",
    "\n",
    "**X-axis**: This axis represents the actual values of the target variable which is the true values from your test data.\n",
    "\n",
    "**Y-axis**: This axis shows the predicted values from my model for each corresponding actual value.\n",
    "\n",
    "**Ideal Predictions (Red Line)**: \n",
    "\n",
    "The red diagonal line represents ideal predictions where the predicted values perfectly match the actual values the points closer to this line signify more accurate predictions.\n",
    "\n",
    "**Scatter Analysis**:\n",
    "\n",
    "The scatter of points around the red line is tighter compared to typical linear regression models, especially for Random Forest, which tends to model non-linear relationships well.\n",
    "\n",
    "**This suggests that the Random Forest Regressor is capturing complex patterns in the data, leading to improved predictive performance**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Short Summary** \n",
    "\n",
    "From the two scatter plots, we can see how well each model predicts the target variable by comparing the predicted values against the actual values.\n",
    "\n",
    "In the **Linear Regression plot**, the points are more scattered, especially at the higher end of the actual values, which shows that the model struggles to make accurate predictions. The predicted values deviate more significantly from the actual values, showing that the model isn't capturing the patterns well.\n",
    "\n",
    "On the other hand, the **Random Forest Regressor** plot shows a tighter clustering of points around the red prediction line, this shows that it makes more accurate predictions overall. The Random Forest model seems to better capture the relationship between the features and the target variable, leading to fewer errors.\n",
    "\n",
    "Overall, based on these visualizations, the ***Random Forest Regressor performs better than the Linear Regression model***, as it shows more precise predictions with less scatter. This is reflected in the higher R² score and lower error metrics for the Random Forest model as well.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
